{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import NBER graph and add department data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import nltk.metrics as nm\n",
    "import editdistance\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load NBER Graph from File\n",
    "# NBER graph contains coauthorship edges annotated with JEL codes \n",
    "path = '../save/nber.graphml'\n",
    "G = nx.read_graphml(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the list of edges that have a certain jelcode \n",
    "def getJELedges(G, jelcode):\n",
    "    links = G.edges()\n",
    "    inds = [jelcode in G[link[0]][link[1]]['jelcode'].split(',') for link in links]\n",
    "    return pd.Series(links)[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getBigJELedges(G, bigJel):\n",
    "    links = G.edges()\n",
    "    inds = [bigJel in re.findall(\"[a-zA-Z]\", G[link[0]][link[1]]['jelcode']) for link in links]\n",
    "    return pd.Series(links)[inds]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Merge in Departments (scraped from REPEC)\n",
    "department = pd.read_csv('../../../work_erica/EconIdeaNetwork/save/REPEC_Paper_Info.csv', delimiter=',')\n",
    "department = department.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "department['authorClean'] = department.Author.apply(lambda x: x.replace(',','').split(' '))\n",
    "department['authorClean'] = department['authorClean'].apply(lambda x: x[1] + x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HACK: Drop duplicates by taking first institution \n",
    "department = department.groupby('authorClean').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Manually Check for matches using Levenstein Distance (tolerance = 2)\n",
    "\n",
    "authorDF = []\n",
    "\n",
    "def getAuthorMatches(author):\n",
    "\n",
    "    matches = pd.DataFrame(ndf.author[ndf.author.apply(lambda x: editdistance.eval(x, author)) < 2])\n",
    "    matches['repecAuthor'] = author\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get list of Author Matches\n",
    "\n",
    "%%time\n",
    "deptMatches = department.authorClean.apply(getAuthorMatches)\n",
    "deptMatches = pd.concat(list(deptMatches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix Author Errors in NBER by merging\n",
    "# Nodes with wrong names\n",
    "\n",
    "s = deptMatches.groupby('repecAuthor').size()\n",
    "nberAuthorErrors = s[s > 1].index\n",
    "\n",
    "for currAuthor in nberAuthorErrors:\n",
    "\n",
    "    prevAuthorNames = deptMatches[deptMatches.repecAuthor == currAuthor].author.values\n",
    "\n",
    "    # For each prev name, collect all edges\n",
    "    # then delete node\n",
    "\n",
    "    allPrevEdges = []\n",
    "\n",
    "    for prevName in prevAuthorNames:\n",
    "\n",
    "        prevEdges = G.edges(prevName)\n",
    "        prevEdges = [x[1] for x in prevEdges]\n",
    "        allPrevEdges = allPrevEdges + prevEdges\n",
    "\n",
    "        G.remove_node(prevName)\n",
    "\n",
    "    # Create new node with full set of edges\n",
    "\n",
    "    for target in allPrevEdges:\n",
    "        G.add_edge(prevAuthorNames[0], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge Department Affiliations onto Author Matches\n",
    "authDept = pd.merge(deptMatches, department, how='left', left_on='repecAuthor', right_on='authorClean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authDept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add department affiliations to G\n",
    "for author in authDept\n",
    "    authDept[\"Institution\"]\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic full-graph summary stats\n",
    "degree_dist = nx.degree_histogram(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine JEL subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getJELSubgraph generates the subgraph of G containing all papers with \n",
    "# JEL code 'jelcode'\n",
    "def getJELSubgraph(G, jelcode):\n",
    "    SG = nx.Graph()\n",
    "    sge = [e for e in G.edges(data=True) if jelcode in e[2]['jelcode']]\n",
    "    SG.add_edges_from(sge)\n",
    "    return SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getBigJELSubgraph generates the subgraph of G containing all papers with \n",
    "# JEL category (first letter) 'jelcode'\n",
    "def getBigJELSubgraph(G, jelcode):\n",
    "    SG = nx.Graph()\n",
    "    sge = [e for e in G.edges(data=True) if jelcode in re.findall(\"[a-zA-Z]\", e[2]['jelcode'])[0]]\n",
    "    SG.add_edges_from(sge)\n",
    "    return SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the Mean all-pairs node connectivity of a JEL Code\n",
    "def getConnEst(G, jelcode):\n",
    "    return np.mean(nx.all_pairs_node_connectivity(getJELSubgraph(G, jelcode)).values()[0].values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get set of JEL super-categories (just first letter)\n",
    "def getBigJELs(jels):\n",
    "    bigJels = map(lambda x: re.findall(\"[a-zA-Z]\",x)[0], jels)\n",
    "    return set(bigJels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get List of JEL codes\n",
    "e = G.edges(data=True)\n",
    "jels = set(','.join([x[2]['jelcode'] for x in e]).split(','))\n",
    "bigJels = getBigJELs(jels)\n",
    "\n",
    "# Get List of Nodes\n",
    "n = G.nodes()\n",
    "ndf = pd.DataFrame(n, columns=['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save coauthorship network for each JEL category\n",
    "jelGraphs = {}\n",
    "for currCode in bigJels:\n",
    "    jelGraphs[currCode] = getBigJELSubgraph(G, currCode)\n",
    "    nx.write_graphml(jelGraphs[currCode], '../save/JEL' + currCode + '.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Examine institutional subgraphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get list of NBER authors corresponding to Institution\n",
    "\n",
    "instGraphs = {}\n",
    "insts = department.Institution.unique()\n",
    "\n",
    "# save coauthorship network for each institution\n",
    "for currInst in insts:\n",
    "    instGraphs[currInst] = G.subgraph(list(authDept[authDept.Institution == currInst].author))\n",
    "    nx.write_graphml(instGraphs[currInst], \\\n",
    "                     '../save/' + currInst.replace(',','').replace(' ','_') + '.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Summarize Institutional Graphs\n",
    "\n",
    "instDf = pd.DataFrame()\n",
    "instDf['Institution'] = insts\n",
    "instDf['Graph'] = instDf.Institution.apply(lambda x: instGraphs[x])\n",
    "# Avg Degree, Avg Centrality, Number of Components, Number of Nodes, \n",
    "# Longest Shortest Path, Total # of Papers, Avg # of Papers, % of Papers within Dept\n",
    "# Rank\n",
    "\n",
    "instDf['AvgDegree'] = instDf.Graph.apply(lambda x: \\\n",
    "                                         np.mean(nx.degree(x, x.nodes()).values()))\n",
    "instDf['nNodes'] = instDf.Graph.apply(lambda x: len(x.nodes()))\n",
    "\n",
    "# Drop Empty Departments\n",
    "instDf = instDf[instDf.nNodes != 0]\n",
    "\n",
    "instDf['nCC'] = instDf.Graph.apply(lambda x: \\\n",
    "                                   len([c for c in nx.connected_components(x)]))\n",
    "instDf['AvgSizeCC'] = instDf.Graph.apply(lambda x: \\\n",
    "                                         np.mean([len(c) for c in nx.connected_components(x)]))\n",
    "instDf['MaxSizeCC'] = instDf.Graph.apply(lambda x: \\\n",
    "                                         np.max([len(c) for c in nx.connected_components(x)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NBERPapers = pd.read_csv('../save/NBER_Paper_Info.1.csv', delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netflix feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a JEL lookup table to map jels to indices                                                     \n",
    "jelLookup = dict()\n",
    "for i, jel in enumerate(jels):\n",
    "    jelLookup[jel] = i\n",
    "\n",
    "# make an array of authors x JELs \n",
    "# to count how many papers in each JEL someone has\n",
    "authors = nx.nodes(G)\n",
    "authorCodes = np.zeros((len(authors), len(jels)))\n",
    "for a in range(len(authors)):\n",
    "    papers = G.edges(authors[a])\n",
    "    for p in papers:\n",
    "        paperAttrs = G.get_edge_data(p[0], p[1])\n",
    "        paperJels  = paperAttrs['jelcode'].split(',')\n",
    "        jelInds = [jelLookup[jel] for jel in paperJels]\n",
    "        authorCodes[a, jelInds] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PageRanks\n",
    "ranks = nx.pagerank(G)\n",
    "\n",
    "# add to graph                                                                  \n",
    "nx.set_node_attributes(G, 'rank', ranks)\n",
    "\n",
    "# in case we want to look at the top authors                                    \n",
    "sortedRanks = sorted(ranks.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract PageRank to a vector                                                  \n",
    "authors = G.nodes()\n",
    "nodeRanks = np.empty(len(authors))\n",
    "for i in range(len(authors)):\n",
    "    nodeRanks[i] = ranks.get(authors[i])\n",
    "nodeRanks = np.reshape(nodeRanks, (len(nodeRanks),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make feature dataframe\n",
    "data = np.hstack((nodeRanks,authorCodes))\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['rank'] + [jel for jel in jels]\n",
    "df['author'] = authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G.nodes(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO \n",
    "\n",
    "- Aggregate JELs by letter \n",
    "- Add JELS as author attributes.\n",
    "- Look at degree distribution of subgraphs given by each JEL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
